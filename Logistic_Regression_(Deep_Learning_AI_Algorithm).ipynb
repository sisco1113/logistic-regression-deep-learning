{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sisco1113/logistic-regression-deep-learning-AI-algorithm/blob/main/Logistic_Regression_(Deep_Learning_AI_Algorithm).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-pb0cO4InzF"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#\n",
        "#    1. Number of times pregnant\n",
        "#    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test #    3. Diastolic blood pressure (mm Hg)\n",
        "#    4. Triceps skin fold thickness (mm) #    5. 2-Hour serum insulin (mu U/ml)\n",
        "#    6. Body mass index (weight in kg/(height in m)^2)\n",
        "#    7. Diabetes pedigree function\n",
        "#    8. Age (years)\n",
        "#    9. Class variable (0 or 1)\n",
        "#\n",
        "# complete columns array\n",
        "columns=[\"Number of times pregnant\",\n",
        "           \"Plasma glucose concentration a 2 hours\",\n",
        "           \"Diastolic blood pressure\",\n",
        "           \"Triceps skin fold thickness\",\n",
        "           \"2-Hour serum insulin\",\n",
        "           \"Body mass index\",\n",
        "           \"Diabetes pedigree function\",\n",
        "           \"Age\",\n",
        "           \"Class\"]\n",
        "\n",
        "pima_data = pd.read_csv(\"pima-diabetes.csv\", names=columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWwfY5RKInzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f534cef8-8a76-454e-9f52-dc0cde8a1d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension: \n",
            " (768, 9)\n",
            "Datatype: \n",
            " Number of times pregnant                    int64\n",
            "Plasma glucose concentration a 2 hours      int64\n",
            "Diastolic blood pressure                    int64\n",
            "Triceps skin fold thickness                 int64\n",
            "2-Hour serum insulin                        int64\n",
            "Body mass index                           float64\n",
            "Diabetes pedigree function                float64\n",
            "Age                                         int64\n",
            "Class                                       int64\n",
            "dtype: object\n",
            "First 5 rows: \n",
            "    Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "0                         6                                     148   \n",
            "1                         1                                      85   \n",
            "2                         8                                     183   \n",
            "3                         1                                      89   \n",
            "4                         0                                     137   \n",
            "\n",
            "   Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "0                        72                           35   \n",
            "1                        66                           29   \n",
            "2                        64                            0   \n",
            "3                        66                           23   \n",
            "4                        40                           35   \n",
            "\n",
            "   2-Hour serum insulin  Body mass index  Diabetes pedigree function  Age  \\\n",
            "0                     0             33.6                       0.627   50   \n",
            "1                     0             26.6                       0.351   31   \n",
            "2                     0             23.3                       0.672   32   \n",
            "3                    94             28.1                       0.167   21   \n",
            "4                   168             43.1                       2.288   33   \n",
            "\n",
            "   Class  \n",
            "0      1  \n",
            "1      0  \n",
            "2      1  \n",
            "3      0  \n",
            "4      1  \n",
            "Mean, count, std, min, max, etc. for each attribute: \n",
            "        Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "count                768.000000                              768.000000   \n",
            "mean                   3.845052                              120.894531   \n",
            "std                    3.369578                               31.972618   \n",
            "min                    0.000000                                0.000000   \n",
            "25%                    1.000000                               99.000000   \n",
            "50%                    3.000000                              117.000000   \n",
            "75%                    6.000000                              140.250000   \n",
            "max                   17.000000                              199.000000   \n",
            "\n",
            "       Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "count                768.000000                   768.000000   \n",
            "mean                  69.105469                    20.536458   \n",
            "std                   19.355807                    15.952218   \n",
            "min                    0.000000                     0.000000   \n",
            "25%                   62.000000                     0.000000   \n",
            "50%                   72.000000                    23.000000   \n",
            "75%                   80.000000                    32.000000   \n",
            "max                  122.000000                    99.000000   \n",
            "\n",
            "       2-Hour serum insulin  Body mass index  Diabetes pedigree function  \\\n",
            "count            768.000000       768.000000                  768.000000   \n",
            "mean              79.799479        31.992578                    0.471876   \n",
            "std              115.244002         7.884160                    0.331329   \n",
            "min                0.000000         0.000000                    0.078000   \n",
            "25%                0.000000        27.300000                    0.243750   \n",
            "50%               30.500000        32.000000                    0.372500   \n",
            "75%              127.250000        36.600000                    0.626250   \n",
            "max              846.000000        67.100000                    2.420000   \n",
            "\n",
            "              Age       Class  \n",
            "count  768.000000  768.000000  \n",
            "mean    33.240885    0.348958  \n",
            "std     11.760232    0.476951  \n",
            "min     21.000000    0.000000  \n",
            "25%     24.000000    0.000000  \n",
            "50%     29.000000    0.000000  \n",
            "75%     41.000000    1.000000  \n",
            "max     81.000000    1.000000  \n"
          ]
        }
      ],
      "source": [
        "# show dimension, datatype, and first 5 rows of pima_data.\n",
        "# use shape, dtypes, describe\n",
        "# for each attribute, show mean, count, std, min, max, etc\n",
        "# use describe\n",
        "print(\"Dimension: \\n\", pima_data.shape)\n",
        "print(\"Datatype: \\n\", pima_data.dtypes)\n",
        "print(\"First 5 rows: \\n\", pima_data.head())\n",
        "print(\"Mean, count, std, min, max, etc. for each attribute: \\n\", pima_data.describe())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nbn4BtBInzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b461ad-8104-42b9-8a65-d29f3b521c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized attributes: \n",
            "        Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "count                768.000000                              768.000000   \n",
            "mean                   0.226180                                0.607510   \n",
            "std                    0.198210                                0.160666   \n",
            "min                    0.000000                                0.000000   \n",
            "25%                    0.058824                                0.497487   \n",
            "50%                    0.176471                                0.587940   \n",
            "75%                    0.352941                                0.704774   \n",
            "max                    1.000000                                1.000000   \n",
            "\n",
            "       Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "count                768.000000                   768.000000   \n",
            "mean                   0.566438                     0.207439   \n",
            "std                    0.158654                     0.161134   \n",
            "min                    0.000000                     0.000000   \n",
            "25%                    0.508197                     0.000000   \n",
            "50%                    0.590164                     0.232323   \n",
            "75%                    0.655738                     0.323232   \n",
            "max                    1.000000                     1.000000   \n",
            "\n",
            "       2-Hour serum insulin  Body mass index  Diabetes pedigree function  \\\n",
            "count            768.000000       768.000000                  768.000000   \n",
            "mean               0.094326         0.476790                    0.168179   \n",
            "std                0.136222         0.117499                    0.141473   \n",
            "min                0.000000         0.000000                    0.000000   \n",
            "25%                0.000000         0.406855                    0.070773   \n",
            "50%                0.036052         0.476900                    0.125747   \n",
            "75%                0.150414         0.545455                    0.234095   \n",
            "max                1.000000         1.000000                    1.000000   \n",
            "\n",
            "              Age  \n",
            "count  768.000000  \n",
            "mean     0.204015  \n",
            "std      0.196004  \n",
            "min      0.000000  \n",
            "25%      0.050000  \n",
            "50%      0.133333  \n",
            "75%      0.333333  \n",
            "max      1.000000  \n"
          ]
        }
      ],
      "source": [
        "#\n",
        "#We are going to normalize(scale) the values of each attributes.\n",
        "#\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Choose one of these\n",
        "# normalize every attribute (except target attribute) using MinMaxScaler\n",
        "#scaler = MinMaxScaler()\n",
        "# Instead of ‘MinMaxScaler’, you can also use ‘StandardScaler’\n",
        "#scaler = StandardScaler()\n",
        "\n",
        "#\n",
        "#*** DON’T normalize target(class) attribute\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "in_columns=columns[:-1]\n",
        "\n",
        "\n",
        "df_scaled = scaler.fit_transform(pima_data[in_columns].values)\n",
        "pima_data_norm= pd.DataFrame(df_scaled, columns=in_columns)\n",
        "print(\"Normalized attributes: \\n\", pima_data_norm.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwxAv9ydInzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7b36a3-a62a-4a3d-fac6-b49db68f376e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: \n",
            " (537, 8)\n",
            "X_test: \n",
            " (231, 8)\n",
            "Y_train: \n",
            " (537,)\n",
            "Y_test: \n",
            " (231,)\n",
            "First 5 rows of X_train:\n",
            "      Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "334                         1                                      95   \n",
            "139                         5                                     105   \n",
            "485                         0                                     135   \n",
            "547                         4                                     131   \n",
            "18                          1                                     103   \n",
            "\n",
            "     Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "334                        60                           18   \n",
            "139                        72                           29   \n",
            "485                        68                           42   \n",
            "547                        68                           21   \n",
            "18                         30                           38   \n",
            "\n",
            "     2-Hour serum insulin  Body mass index  Diabetes pedigree function  Age  \n",
            "334                    58             23.9                       0.260   22  \n",
            "139                   325             36.9                       0.159   28  \n",
            "485                   250             42.3                       0.365   24  \n",
            "547                   166             33.1                       0.160   28  \n",
            "18                     83             43.3                       0.183   33  \n",
            "First 5 rows of X_test:\n",
            "      Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "668                         6                                      98   \n",
            "324                         2                                     112   \n",
            "624                         2                                     108   \n",
            "690                         8                                     107   \n",
            "473                         7                                     136   \n",
            "\n",
            "     Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "668                        58                           33   \n",
            "324                        75                           32   \n",
            "624                        64                            0   \n",
            "690                        80                            0   \n",
            "473                        90                            0   \n",
            "\n",
            "     2-Hour serum insulin  Body mass index  Diabetes pedigree function  Age  \n",
            "668                   190             34.0                       0.430   43  \n",
            "324                     0             35.7                       0.148   21  \n",
            "624                     0             30.8                       0.158   21  \n",
            "690                     0             24.6                       0.856   34  \n",
            "473                     0             29.9                       0.210   50  \n",
            "First 5 rows of Y_train:\n",
            " 334    0\n",
            "139    0\n",
            "485    1\n",
            "547    0\n",
            "18     0\n",
            "Name: Class, dtype: int64\n",
            "First 5 rows of Y_test:\n",
            " 668    0\n",
            "324    0\n",
            "624    0\n",
            "690    0\n",
            "473    0\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# With .pop() command, ‘class’ target attribute is extracted.\n",
        "# select input attributes without target attributes\n",
        "# refer to HW 1 and create Y & X in HW 1\n",
        "target_attribute = pima_data.pop('Class')\n",
        "input_attributes = pima_data\n",
        "\n",
        "Y = target_attribute\n",
        "X = input_attributes\n",
        "\n",
        "# split X, Y into X_train, X_test, Y_train, Y_test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "#  Show that split is correctly done\n",
        "# you can show the shape of each data & first 5 rows of each data\n",
        "print(\"X_train: \\n\", X_train.shape)\n",
        "print(\"X_test: \\n\", X_test.shape)\n",
        "print(\"Y_train: \\n\", Y_train.shape)\n",
        "print(\"Y_test: \\n\", Y_test.shape)\n",
        "\n",
        "print(\"First 5 rows of X_train:\\n\", X_train.head())\n",
        "print(\"First 5 rows of X_test:\\n\", X_test.head())\n",
        "print(\"First 5 rows of Y_train:\\n\", Y_train.head())\n",
        "print(\"First 5 rows of Y_test:\\n\", Y_test.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EeX400wInzM"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# In the following, use sigmoid activation function and define input_dim model.add(Dense(1, OOO, OOO))\n",
        "model.add(Dense(1, activation = 'sigmoid', input_dim=8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cBIKer0InzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f941dc-1c6f-4772-f6b6-ee42a41c3b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 2s 11ms/step - loss: 17.1381 - accuracy: 0.3240 - val_loss: 16.7084 - val_accuracy: 0.3377\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 15.0392 - accuracy: 0.3538 - val_loss: 14.9538 - val_accuracy: 0.3550\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 13.9476 - accuracy: 0.3426 - val_loss: 14.0600 - val_accuracy: 0.4113\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 13.4091 - accuracy: 0.3501 - val_loss: 13.5427 - val_accuracy: 0.4069\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 13.0127 - accuracy: 0.3594 - val_loss: 13.1941 - val_accuracy: 0.4199\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 12.6813 - accuracy: 0.3650 - val_loss: 12.8499 - val_accuracy: 0.4242\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 12.3659 - accuracy: 0.3724 - val_loss: 12.5233 - val_accuracy: 0.4329\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 12.0910 - accuracy: 0.3836 - val_loss: 12.2082 - val_accuracy: 0.4545\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 11.7783 - accuracy: 0.3873 - val_loss: 11.9545 - val_accuracy: 0.4545\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 11.5137 - accuracy: 0.3929 - val_loss: 11.6915 - val_accuracy: 0.4459\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 11.2548 - accuracy: 0.3966 - val_loss: 11.4335 - val_accuracy: 0.4459\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 10.9982 - accuracy: 0.3948 - val_loss: 11.2432 - val_accuracy: 0.4286\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 10.7680 - accuracy: 0.3948 - val_loss: 11.0299 - val_accuracy: 0.4286\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 10.5745 - accuracy: 0.4022 - val_loss: 10.7966 - val_accuracy: 0.4416\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 10.3243 - accuracy: 0.4004 - val_loss: 10.6359 - val_accuracy: 0.4329\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 10.1312 - accuracy: 0.4078 - val_loss: 10.4063 - val_accuracy: 0.4372\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 9.9134 - accuracy: 0.4060 - val_loss: 10.2118 - val_accuracy: 0.4416\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 9.7069 - accuracy: 0.4041 - val_loss: 9.9998 - val_accuracy: 0.4372\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 9.5076 - accuracy: 0.4153 - val_loss: 9.7679 - val_accuracy: 0.4416\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 9.2912 - accuracy: 0.4209 - val_loss: 9.5694 - val_accuracy: 0.4416\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 9.0878 - accuracy: 0.4115 - val_loss: 9.3733 - val_accuracy: 0.4329\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 8.8866 - accuracy: 0.4153 - val_loss: 9.1597 - val_accuracy: 0.4329\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 8.6802 - accuracy: 0.4134 - val_loss: 8.9486 - val_accuracy: 0.4372\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 8.4780 - accuracy: 0.4283 - val_loss: 8.6986 - val_accuracy: 0.4459\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 8.2562 - accuracy: 0.4153 - val_loss: 8.5494 - val_accuracy: 0.4372\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 8.0572 - accuracy: 0.4134 - val_loss: 8.3207 - val_accuracy: 0.4372\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 7.8483 - accuracy: 0.4190 - val_loss: 8.1051 - val_accuracy: 0.4372\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 7.6529 - accuracy: 0.4153 - val_loss: 7.9113 - val_accuracy: 0.4329\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 7.4268 - accuracy: 0.4097 - val_loss: 7.6571 - val_accuracy: 0.4416\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 7.2278 - accuracy: 0.4264 - val_loss: 7.4574 - val_accuracy: 0.4372\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 7.0574 - accuracy: 0.4060 - val_loss: 7.2729 - val_accuracy: 0.4242\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6.8157 - accuracy: 0.4134 - val_loss: 7.0252 - val_accuracy: 0.4372\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6.6209 - accuracy: 0.4115 - val_loss: 6.8611 - val_accuracy: 0.4416\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6.4026 - accuracy: 0.4115 - val_loss: 6.6170 - val_accuracy: 0.4329\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6.2246 - accuracy: 0.4246 - val_loss: 6.4111 - val_accuracy: 0.4329\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6.0040 - accuracy: 0.4078 - val_loss: 6.2323 - val_accuracy: 0.4416\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5.8015 - accuracy: 0.4060 - val_loss: 5.9782 - val_accuracy: 0.4372\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 5.5952 - accuracy: 0.4209 - val_loss: 5.7763 - val_accuracy: 0.4372\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 5.3963 - accuracy: 0.4097 - val_loss: 5.6112 - val_accuracy: 0.4416\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 5.2163 - accuracy: 0.4153 - val_loss: 5.3956 - val_accuracy: 0.4286\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 5.0113 - accuracy: 0.4041 - val_loss: 5.1697 - val_accuracy: 0.4286\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 4.7890 - accuracy: 0.4246 - val_loss: 4.9898 - val_accuracy: 0.4329\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 4.5956 - accuracy: 0.4115 - val_loss: 4.7977 - val_accuracy: 0.4329\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 4.4189 - accuracy: 0.4190 - val_loss: 4.5742 - val_accuracy: 0.4416\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 4.1960 - accuracy: 0.4115 - val_loss: 4.3888 - val_accuracy: 0.4372\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 4.0231 - accuracy: 0.4115 - val_loss: 4.2255 - val_accuracy: 0.4329\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 3.8210 - accuracy: 0.4097 - val_loss: 3.9853 - val_accuracy: 0.4416\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3.6305 - accuracy: 0.4022 - val_loss: 3.7824 - val_accuracy: 0.4286\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3.4523 - accuracy: 0.4190 - val_loss: 3.6025 - val_accuracy: 0.4329\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3.2563 - accuracy: 0.4134 - val_loss: 3.4411 - val_accuracy: 0.4286\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4411 - accuracy: 0.4286\n",
            "Loss:  3.441102981567383\n",
            "Accuracy:  0.4285714328289032\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# 1) use ‘adam’ optimizer, 2) loss function is binary_crossentropy\n",
        "# 3) metrics = accuracy\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# change epoch values\n",
        "model.fit(X_train, Y_train, batch_size=20, epochs=50, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=30, epochs=60, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "apQKdT-hqsCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d8714b-7847-4805-8bb7-01e25e7ae8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 3.1061 - accuracy: 0.4134 - val_loss: 3.3080 - val_accuracy: 0.4329\n",
            "Epoch 2/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9996 - accuracy: 0.4097 - val_loss: 3.1921 - val_accuracy: 0.4329\n",
            "Epoch 3/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8631 - accuracy: 0.4097 - val_loss: 3.0516 - val_accuracy: 0.4329\n",
            "Epoch 4/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.7503 - accuracy: 0.4302 - val_loss: 2.9364 - val_accuracy: 0.4286\n",
            "Epoch 5/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.6400 - accuracy: 0.4190 - val_loss: 2.8292 - val_accuracy: 0.4286\n",
            "Epoch 6/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.5184 - accuracy: 0.4264 - val_loss: 2.7042 - val_accuracy: 0.4372\n",
            "Epoch 7/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.4145 - accuracy: 0.4320 - val_loss: 2.5915 - val_accuracy: 0.4416\n",
            "Epoch 8/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.3036 - accuracy: 0.4358 - val_loss: 2.4725 - val_accuracy: 0.4502\n",
            "Epoch 9/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.2040 - accuracy: 0.4376 - val_loss: 2.3731 - val_accuracy: 0.4545\n",
            "Epoch 10/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0996 - accuracy: 0.4562 - val_loss: 2.2590 - val_accuracy: 0.4459\n",
            "Epoch 11/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.9948 - accuracy: 0.4488 - val_loss: 2.1571 - val_accuracy: 0.4242\n",
            "Epoch 12/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.9056 - accuracy: 0.4637 - val_loss: 2.0434 - val_accuracy: 0.4762\n",
            "Epoch 13/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8203 - accuracy: 0.4507 - val_loss: 1.9761 - val_accuracy: 0.4156\n",
            "Epoch 14/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7122 - accuracy: 0.4637 - val_loss: 1.8427 - val_accuracy: 0.4632\n",
            "Epoch 15/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6265 - accuracy: 0.4674 - val_loss: 1.7556 - val_accuracy: 0.4545\n",
            "Epoch 16/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5454 - accuracy: 0.4674 - val_loss: 1.6634 - val_accuracy: 0.4416\n",
            "Epoch 17/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4666 - accuracy: 0.4674 - val_loss: 1.5724 - val_accuracy: 0.4545\n",
            "Epoch 18/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4037 - accuracy: 0.4916 - val_loss: 1.4867 - val_accuracy: 0.4502\n",
            "Epoch 19/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.3188 - accuracy: 0.4730 - val_loss: 1.4018 - val_accuracy: 0.4589\n",
            "Epoch 20/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.2468 - accuracy: 0.4823 - val_loss: 1.3209 - val_accuracy: 0.4502\n",
            "Epoch 21/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.1798 - accuracy: 0.4972 - val_loss: 1.2463 - val_accuracy: 0.4502\n",
            "Epoch 22/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1254 - accuracy: 0.4972 - val_loss: 1.1751 - val_accuracy: 0.4589\n",
            "Epoch 23/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.0656 - accuracy: 0.5438 - val_loss: 1.1050 - val_accuracy: 0.4892\n",
            "Epoch 24/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0069 - accuracy: 0.5493 - val_loss: 1.0487 - val_accuracy: 0.4675\n",
            "Epoch 25/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9682 - accuracy: 0.5624 - val_loss: 0.9979 - val_accuracy: 0.4892\n",
            "Epoch 26/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9170 - accuracy: 0.5400 - val_loss: 0.9357 - val_accuracy: 0.4935\n",
            "Epoch 27/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8810 - accuracy: 0.5885 - val_loss: 0.9083 - val_accuracy: 0.4892\n",
            "Epoch 28/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8428 - accuracy: 0.5661 - val_loss: 0.8553 - val_accuracy: 0.5065\n",
            "Epoch 29/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8018 - accuracy: 0.5922 - val_loss: 0.8116 - val_accuracy: 0.5498\n",
            "Epoch 30/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7805 - accuracy: 0.5959 - val_loss: 0.7796 - val_accuracy: 0.5714\n",
            "Epoch 31/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.6089 - val_loss: 0.7542 - val_accuracy: 0.5714\n",
            "Epoch 32/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7267 - accuracy: 0.5978 - val_loss: 0.7280 - val_accuracy: 0.6017\n",
            "Epoch 33/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7096 - accuracy: 0.6127 - val_loss: 0.7078 - val_accuracy: 0.6234\n",
            "Epoch 34/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6954 - accuracy: 0.6331 - val_loss: 0.7080 - val_accuracy: 0.5931\n",
            "Epoch 35/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6871 - accuracy: 0.6238 - val_loss: 0.6737 - val_accuracy: 0.6580\n",
            "Epoch 36/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6695 - accuracy: 0.6276 - val_loss: 0.6665 - val_accuracy: 0.6667\n",
            "Epoch 37/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6276 - val_loss: 0.6515 - val_accuracy: 0.6710\n",
            "Epoch 38/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6555 - accuracy: 0.6406 - val_loss: 0.6402 - val_accuracy: 0.6580\n",
            "Epoch 39/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6443 - val_loss: 0.6326 - val_accuracy: 0.6883\n",
            "Epoch 40/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6555 - val_loss: 0.6233 - val_accuracy: 0.6883\n",
            "Epoch 41/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6536 - val_loss: 0.6210 - val_accuracy: 0.6970\n",
            "Epoch 42/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6558 - accuracy: 0.6406 - val_loss: 0.6315 - val_accuracy: 0.6840\n",
            "Epoch 43/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6292 - accuracy: 0.6667 - val_loss: 0.6236 - val_accuracy: 0.7013\n",
            "Epoch 44/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6834 - val_loss: 0.6050 - val_accuracy: 0.6926\n",
            "Epoch 45/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6778 - val_loss: 0.5991 - val_accuracy: 0.7100\n",
            "Epoch 46/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6249 - accuracy: 0.6723 - val_loss: 0.6068 - val_accuracy: 0.7186\n",
            "Epoch 47/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6667 - val_loss: 0.5939 - val_accuracy: 0.7100\n",
            "Epoch 48/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6120 - accuracy: 0.6927 - val_loss: 0.5900 - val_accuracy: 0.7100\n",
            "Epoch 49/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6101 - accuracy: 0.6816 - val_loss: 0.5882 - val_accuracy: 0.7229\n",
            "Epoch 50/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.6797 - val_loss: 0.5878 - val_accuracy: 0.7229\n",
            "Epoch 51/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.6667 - val_loss: 0.6194 - val_accuracy: 0.7100\n",
            "Epoch 52/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.6704 - val_loss: 0.5834 - val_accuracy: 0.7100\n",
            "Epoch 53/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6853 - val_loss: 0.5871 - val_accuracy: 0.7273\n",
            "Epoch 54/60\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6064 - accuracy: 0.6816 - val_loss: 0.5894 - val_accuracy: 0.7013\n",
            "Epoch 55/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.7020 - val_loss: 0.5801 - val_accuracy: 0.7100\n",
            "Epoch 56/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.6797 - val_loss: 0.5788 - val_accuracy: 0.7100\n",
            "Epoch 57/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.6909 - val_loss: 0.5796 - val_accuracy: 0.7100\n",
            "Epoch 58/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.6872 - val_loss: 0.5800 - val_accuracy: 0.7186\n",
            "Epoch 59/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6006 - accuracy: 0.6853 - val_loss: 0.5782 - val_accuracy: 0.7273\n",
            "Epoch 60/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6033 - accuracy: 0.6723 - val_loss: 0.5970 - val_accuracy: 0.7273\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7273\n",
            "Loss:  0.5969664454460144\n",
            "Accuracy:  0.7272727489471436\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=25, epochs=55, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "2JzPIuVgqyA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e477cfa-1d38-479d-e2c8-b2d28b499421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6051 - accuracy: 0.6797 - val_loss: 0.5773 - val_accuracy: 0.7100\n",
            "Epoch 2/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.6834 - val_loss: 0.5768 - val_accuracy: 0.7273\n",
            "Epoch 3/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6088 - accuracy: 0.6816 - val_loss: 0.6003 - val_accuracy: 0.7186\n",
            "Epoch 4/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6946 - val_loss: 0.6207 - val_accuracy: 0.6840\n",
            "Epoch 5/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6797 - val_loss: 0.5810 - val_accuracy: 0.7403\n",
            "Epoch 6/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5958 - accuracy: 0.6853 - val_loss: 0.5733 - val_accuracy: 0.7186\n",
            "Epoch 7/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.6909 - val_loss: 0.5738 - val_accuracy: 0.7273\n",
            "Epoch 8/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.6909 - val_loss: 0.5865 - val_accuracy: 0.7532\n",
            "Epoch 9/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.6853 - val_loss: 0.5738 - val_accuracy: 0.7273\n",
            "Epoch 10/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.6965 - val_loss: 0.5727 - val_accuracy: 0.7186\n",
            "Epoch 11/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.6927 - val_loss: 0.5810 - val_accuracy: 0.7359\n",
            "Epoch 12/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.6816 - val_loss: 0.5717 - val_accuracy: 0.7273\n",
            "Epoch 13/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.6909 - val_loss: 0.5728 - val_accuracy: 0.7100\n",
            "Epoch 14/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5986 - accuracy: 0.6983 - val_loss: 0.5738 - val_accuracy: 0.7186\n",
            "Epoch 15/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6927 - val_loss: 0.5845 - val_accuracy: 0.7359\n",
            "Epoch 16/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.6723 - val_loss: 0.6276 - val_accuracy: 0.6580\n",
            "Epoch 17/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6760 - val_loss: 0.5806 - val_accuracy: 0.7446\n",
            "Epoch 18/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.6685 - val_loss: 0.5713 - val_accuracy: 0.7186\n",
            "Epoch 19/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5928 - accuracy: 0.6909 - val_loss: 0.5781 - val_accuracy: 0.7446\n",
            "Epoch 20/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5907 - accuracy: 0.7039 - val_loss: 0.5704 - val_accuracy: 0.7186\n",
            "Epoch 21/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.6834 - val_loss: 0.5765 - val_accuracy: 0.6926\n",
            "Epoch 22/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.7095 - val_loss: 0.5705 - val_accuracy: 0.7229\n",
            "Epoch 23/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5880 - accuracy: 0.7076 - val_loss: 0.5697 - val_accuracy: 0.7056\n",
            "Epoch 24/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6834 - val_loss: 0.5763 - val_accuracy: 0.7359\n",
            "Epoch 25/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5918 - accuracy: 0.6927 - val_loss: 0.6075 - val_accuracy: 0.7186\n",
            "Epoch 26/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6853 - val_loss: 0.5747 - val_accuracy: 0.7316\n",
            "Epoch 27/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.7058 - val_loss: 0.5700 - val_accuracy: 0.7186\n",
            "Epoch 28/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7076 - val_loss: 0.5713 - val_accuracy: 0.7359\n",
            "Epoch 29/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5880 - accuracy: 0.7076 - val_loss: 0.5724 - val_accuracy: 0.6970\n",
            "Epoch 30/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.6778 - val_loss: 0.5690 - val_accuracy: 0.7273\n",
            "Epoch 31/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.6816 - val_loss: 0.5715 - val_accuracy: 0.7056\n",
            "Epoch 32/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.7002 - val_loss: 0.5778 - val_accuracy: 0.6883\n",
            "Epoch 33/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.6927 - val_loss: 0.5784 - val_accuracy: 0.7359\n",
            "Epoch 34/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.6853 - val_loss: 0.5692 - val_accuracy: 0.7100\n",
            "Epoch 35/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.7169 - val_loss: 0.5670 - val_accuracy: 0.7056\n",
            "Epoch 36/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.7114 - val_loss: 0.5721 - val_accuracy: 0.6970\n",
            "Epoch 37/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.7020 - val_loss: 0.5705 - val_accuracy: 0.7316\n",
            "Epoch 38/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.7132 - val_loss: 0.5692 - val_accuracy: 0.7100\n",
            "Epoch 39/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.6965 - val_loss: 0.5703 - val_accuracy: 0.7013\n",
            "Epoch 40/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.7095 - val_loss: 0.5671 - val_accuracy: 0.7186\n",
            "Epoch 41/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5844 - accuracy: 0.7002 - val_loss: 0.5717 - val_accuracy: 0.7273\n",
            "Epoch 42/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6927 - val_loss: 0.5885 - val_accuracy: 0.7273\n",
            "Epoch 43/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.6872 - val_loss: 0.5691 - val_accuracy: 0.7186\n",
            "Epoch 44/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7002 - val_loss: 0.5676 - val_accuracy: 0.7186\n",
            "Epoch 45/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.6890 - val_loss: 0.5687 - val_accuracy: 0.7229\n",
            "Epoch 46/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.7114 - val_loss: 0.5662 - val_accuracy: 0.7056\n",
            "Epoch 47/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5926 - accuracy: 0.7076 - val_loss: 0.5660 - val_accuracy: 0.7143\n",
            "Epoch 48/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6983 - val_loss: 0.5670 - val_accuracy: 0.7273\n",
            "Epoch 49/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.6927 - val_loss: 0.5852 - val_accuracy: 0.7316\n",
            "Epoch 50/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5859 - accuracy: 0.6890 - val_loss: 0.5674 - val_accuracy: 0.7273\n",
            "Epoch 51/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.6946 - val_loss: 0.5725 - val_accuracy: 0.6970\n",
            "Epoch 52/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7002 - val_loss: 0.5674 - val_accuracy: 0.7273\n",
            "Epoch 53/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6760 - val_loss: 0.6106 - val_accuracy: 0.7056\n",
            "Epoch 54/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5916 - accuracy: 0.6723 - val_loss: 0.5769 - val_accuracy: 0.7316\n",
            "Epoch 55/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.7076 - val_loss: 0.5682 - val_accuracy: 0.6970\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.6970\n",
            "Loss:  0.5682251453399658\n",
            "Accuracy:  0.6969696879386902\n",
            "8/8 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=30, epochs=45, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "z2UX2vl7qx6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4d794a-b52e-4ee6-e660-58a1ce967623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5787 - accuracy: 0.7039 - val_loss: 0.5672 - val_accuracy: 0.7316\n",
            "Epoch 2/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5834 - accuracy: 0.7132 - val_loss: 0.5651 - val_accuracy: 0.7100\n",
            "Epoch 3/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5851 - accuracy: 0.7020 - val_loss: 0.5654 - val_accuracy: 0.7100\n",
            "Epoch 4/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.7039 - val_loss: 0.5626 - val_accuracy: 0.7100\n",
            "Epoch 5/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7114 - val_loss: 0.5670 - val_accuracy: 0.7186\n",
            "Epoch 6/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5797 - accuracy: 0.7076 - val_loss: 0.5650 - val_accuracy: 0.7229\n",
            "Epoch 7/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7076 - val_loss: 0.5864 - val_accuracy: 0.7359\n",
            "Epoch 8/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5891 - accuracy: 0.7151 - val_loss: 0.5746 - val_accuracy: 0.6926\n",
            "Epoch 9/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5900 - accuracy: 0.7002 - val_loss: 0.5635 - val_accuracy: 0.7186\n",
            "Epoch 10/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.6909 - val_loss: 0.5852 - val_accuracy: 0.7403\n",
            "Epoch 11/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.7095 - val_loss: 0.5698 - val_accuracy: 0.7359\n",
            "Epoch 12/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5783 - accuracy: 0.7095 - val_loss: 0.5629 - val_accuracy: 0.7186\n",
            "Epoch 13/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.6965 - val_loss: 0.5634 - val_accuracy: 0.7229\n",
            "Epoch 14/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.7225 - val_loss: 0.5651 - val_accuracy: 0.7013\n",
            "Epoch 15/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5869 - accuracy: 0.6927 - val_loss: 0.5660 - val_accuracy: 0.7229\n",
            "Epoch 16/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7132 - val_loss: 0.5621 - val_accuracy: 0.7100\n",
            "Epoch 17/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5802 - accuracy: 0.7039 - val_loss: 0.5622 - val_accuracy: 0.7273\n",
            "Epoch 18/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5762 - accuracy: 0.7132 - val_loss: 0.5613 - val_accuracy: 0.7186\n",
            "Epoch 19/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5792 - accuracy: 0.7151 - val_loss: 0.5656 - val_accuracy: 0.7273\n",
            "Epoch 20/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.7039 - val_loss: 0.5662 - val_accuracy: 0.7056\n",
            "Epoch 21/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.6965 - val_loss: 0.5887 - val_accuracy: 0.7316\n",
            "Epoch 22/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5850 - accuracy: 0.6965 - val_loss: 0.5741 - val_accuracy: 0.7489\n",
            "Epoch 23/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5824 - accuracy: 0.7058 - val_loss: 0.5610 - val_accuracy: 0.7013\n",
            "Epoch 24/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5793 - accuracy: 0.7002 - val_loss: 0.5656 - val_accuracy: 0.7143\n",
            "Epoch 25/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.7076 - val_loss: 0.5606 - val_accuracy: 0.7100\n",
            "Epoch 26/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.7076 - val_loss: 0.5625 - val_accuracy: 0.7273\n",
            "Epoch 27/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.7151 - val_loss: 0.5687 - val_accuracy: 0.7273\n",
            "Epoch 28/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.7002 - val_loss: 0.5684 - val_accuracy: 0.7316\n",
            "Epoch 29/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.6872 - val_loss: 0.5634 - val_accuracy: 0.7273\n",
            "Epoch 30/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.6946 - val_loss: 0.5699 - val_accuracy: 0.6970\n",
            "Epoch 31/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5832 - accuracy: 0.7039 - val_loss: 0.5612 - val_accuracy: 0.7143\n",
            "Epoch 32/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5779 - accuracy: 0.7039 - val_loss: 0.5620 - val_accuracy: 0.7186\n",
            "Epoch 33/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5798 - accuracy: 0.7114 - val_loss: 0.5617 - val_accuracy: 0.7273\n",
            "Epoch 34/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.7020 - val_loss: 0.5644 - val_accuracy: 0.7186\n",
            "Epoch 35/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5831 - accuracy: 0.7244 - val_loss: 0.5616 - val_accuracy: 0.7316\n",
            "Epoch 36/45\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.6909 - val_loss: 0.5588 - val_accuracy: 0.7186\n",
            "Epoch 37/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5780 - accuracy: 0.7132 - val_loss: 0.5722 - val_accuracy: 0.6926\n",
            "Epoch 38/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.7020 - val_loss: 0.5614 - val_accuracy: 0.7056\n",
            "Epoch 39/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5718 - accuracy: 0.7169 - val_loss: 0.5691 - val_accuracy: 0.7489\n",
            "Epoch 40/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5776 - accuracy: 0.7058 - val_loss: 0.5878 - val_accuracy: 0.7229\n",
            "Epoch 41/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5824 - accuracy: 0.7132 - val_loss: 0.5605 - val_accuracy: 0.7056\n",
            "Epoch 42/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7114 - val_loss: 0.5599 - val_accuracy: 0.7229\n",
            "Epoch 43/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5776 - accuracy: 0.7020 - val_loss: 0.5610 - val_accuracy: 0.7056\n",
            "Epoch 44/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5719 - accuracy: 0.7225 - val_loss: 0.5576 - val_accuracy: 0.7229\n",
            "Epoch 45/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7095 - val_loss: 0.5585 - val_accuracy: 0.7186\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7186\n",
            "Loss:  0.5584720969200134\n",
            "Accuracy:  0.7186146974563599\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=25, epochs=50, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "KRV4swpBqxov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948a16a9-f40d-42c7-b89e-7851fa6bd42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5744 - accuracy: 0.7263 - val_loss: 0.5636 - val_accuracy: 0.7186\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.7095 - val_loss: 0.5602 - val_accuracy: 0.7316\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.7039 - val_loss: 0.5632 - val_accuracy: 0.7229\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.7058 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.7039 - val_loss: 0.5636 - val_accuracy: 0.7359\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5720 - accuracy: 0.7169 - val_loss: 0.5706 - val_accuracy: 0.6926\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5803 - accuracy: 0.7039 - val_loss: 0.5571 - val_accuracy: 0.7359\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.7095 - val_loss: 0.5947 - val_accuracy: 0.6753\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.6872 - val_loss: 0.5677 - val_accuracy: 0.6970\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.7095 - val_loss: 0.5581 - val_accuracy: 0.7143\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7151 - val_loss: 0.5565 - val_accuracy: 0.7273\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5783 - accuracy: 0.7020 - val_loss: 0.5581 - val_accuracy: 0.7316\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.6946 - val_loss: 0.5758 - val_accuracy: 0.7229\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7002 - val_loss: 0.5690 - val_accuracy: 0.7489\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5724 - accuracy: 0.7058 - val_loss: 0.5596 - val_accuracy: 0.7056\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5750 - accuracy: 0.7095 - val_loss: 0.5573 - val_accuracy: 0.7273\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7058 - val_loss: 0.5576 - val_accuracy: 0.7273\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.7039 - val_loss: 0.5658 - val_accuracy: 0.7446\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.7114 - val_loss: 0.5592 - val_accuracy: 0.7403\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5700 - accuracy: 0.7114 - val_loss: 0.5593 - val_accuracy: 0.7576\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7169 - val_loss: 0.5551 - val_accuracy: 0.7143\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.6927 - val_loss: 0.5565 - val_accuracy: 0.7186\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.7114 - val_loss: 0.5560 - val_accuracy: 0.7186\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.7300 - val_loss: 0.5590 - val_accuracy: 0.7359\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5666 - accuracy: 0.7076 - val_loss: 0.5945 - val_accuracy: 0.7143\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.6816 - val_loss: 0.5590 - val_accuracy: 0.7359\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5738 - accuracy: 0.7076 - val_loss: 0.5575 - val_accuracy: 0.7403\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7076 - val_loss: 0.5592 - val_accuracy: 0.7056\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.7169 - val_loss: 0.5535 - val_accuracy: 0.7316\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5781 - accuracy: 0.6983 - val_loss: 0.5555 - val_accuracy: 0.7273\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5652 - accuracy: 0.7281 - val_loss: 0.5740 - val_accuracy: 0.7013\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.7169 - val_loss: 0.5724 - val_accuracy: 0.7316\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7020 - val_loss: 0.5612 - val_accuracy: 0.7446\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.7076 - val_loss: 0.5736 - val_accuracy: 0.7359\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5692 - accuracy: 0.7076 - val_loss: 0.5594 - val_accuracy: 0.7576\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7058 - val_loss: 0.5540 - val_accuracy: 0.7359\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7039 - val_loss: 0.5547 - val_accuracy: 0.7316\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.7114 - val_loss: 0.5638 - val_accuracy: 0.7576\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7039 - val_loss: 0.5696 - val_accuracy: 0.7273\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7076 - val_loss: 0.5539 - val_accuracy: 0.7186\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7281 - val_loss: 0.5506 - val_accuracy: 0.7273\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7114 - val_loss: 0.5537 - val_accuracy: 0.7143\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7188 - val_loss: 0.5654 - val_accuracy: 0.7056\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5743 - accuracy: 0.7076 - val_loss: 0.5508 - val_accuracy: 0.7229\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.7225 - val_loss: 0.5569 - val_accuracy: 0.7489\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.5683 - accuracy: 0.7263 - val_loss: 0.5516 - val_accuracy: 0.7403\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.5650 - accuracy: 0.7095 - val_loss: 0.5545 - val_accuracy: 0.7403\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.5662 - accuracy: 0.7207 - val_loss: 0.5498 - val_accuracy: 0.7403\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.5618 - accuracy: 0.7207 - val_loss: 0.5690 - val_accuracy: 0.7316\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.5694 - accuracy: 0.7132 - val_loss: 0.5527 - val_accuracy: 0.7359\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7359\n",
            "Loss:  0.5527405142784119\n",
            "Accuracy:  0.7359307408332825\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=20, epochs=50, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "IOJsT9HeqxXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290400ba-cc24-4e0d-d0bf-11cddbb3c552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5669 - accuracy: 0.7095 - val_loss: 0.5577 - val_accuracy: 0.7662\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.7095 - val_loss: 0.5540 - val_accuracy: 0.7532\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7132 - val_loss: 0.5568 - val_accuracy: 0.7446\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7225 - val_loss: 0.5541 - val_accuracy: 0.7576\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7039 - val_loss: 0.5643 - val_accuracy: 0.7100\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7263 - val_loss: 0.5755 - val_accuracy: 0.7186\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7132 - val_loss: 0.5481 - val_accuracy: 0.7316\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7151 - val_loss: 0.5491 - val_accuracy: 0.7403\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7300 - val_loss: 0.5490 - val_accuracy: 0.7316\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7039 - val_loss: 0.6029 - val_accuracy: 0.6926\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.7188 - val_loss: 0.5874 - val_accuracy: 0.7186\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7151 - val_loss: 0.5584 - val_accuracy: 0.7532\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7225 - val_loss: 0.5536 - val_accuracy: 0.7706\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5638 - accuracy: 0.7188 - val_loss: 0.5539 - val_accuracy: 0.7662\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7263 - val_loss: 0.5676 - val_accuracy: 0.7273\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7076 - val_loss: 0.5471 - val_accuracy: 0.7403\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7151 - val_loss: 0.5499 - val_accuracy: 0.7403\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7114 - val_loss: 0.5462 - val_accuracy: 0.7403\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7207 - val_loss: 0.5554 - val_accuracy: 0.7489\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7132 - val_loss: 0.5492 - val_accuracy: 0.7186\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7393 - val_loss: 0.5480 - val_accuracy: 0.7229\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.7225 - val_loss: 0.5614 - val_accuracy: 0.6926\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7151 - val_loss: 0.5485 - val_accuracy: 0.7186\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7207 - val_loss: 0.5468 - val_accuracy: 0.7316\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7151 - val_loss: 0.5440 - val_accuracy: 0.7403\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7281 - val_loss: 0.5592 - val_accuracy: 0.7532\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7095 - val_loss: 0.5602 - val_accuracy: 0.7619\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7095 - val_loss: 0.5485 - val_accuracy: 0.7619\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7225 - val_loss: 0.5473 - val_accuracy: 0.7403\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7225 - val_loss: 0.5720 - val_accuracy: 0.7359\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7225 - val_loss: 0.5458 - val_accuracy: 0.7359\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7244 - val_loss: 0.5485 - val_accuracy: 0.7186\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7207 - val_loss: 0.5672 - val_accuracy: 0.7489\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7281 - val_loss: 0.5441 - val_accuracy: 0.7359\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7207 - val_loss: 0.6015 - val_accuracy: 0.7056\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5715 - accuracy: 0.6965 - val_loss: 0.5476 - val_accuracy: 0.7576\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5638 - accuracy: 0.7225 - val_loss: 0.5550 - val_accuracy: 0.7706\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7244 - val_loss: 0.5573 - val_accuracy: 0.7619\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7244 - val_loss: 0.5424 - val_accuracy: 0.7359\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7207 - val_loss: 0.5438 - val_accuracy: 0.7403\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7151 - val_loss: 0.5478 - val_accuracy: 0.7576\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.7095 - val_loss: 0.5579 - val_accuracy: 0.7100\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7356 - val_loss: 0.5691 - val_accuracy: 0.7403\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7244 - val_loss: 0.5410 - val_accuracy: 0.7316\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7151 - val_loss: 0.5447 - val_accuracy: 0.7532\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7169 - val_loss: 0.5429 - val_accuracy: 0.7273\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7281 - val_loss: 0.5399 - val_accuracy: 0.7403\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7076 - val_loss: 0.5444 - val_accuracy: 0.7532\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5502 - accuracy: 0.7281 - val_loss: 0.5634 - val_accuracy: 0.6926\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5723 - accuracy: 0.7132 - val_loss: 0.5482 - val_accuracy: 0.7186\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7186\n",
            "Loss:  0.54819256067276\n",
            "Accuracy:  0.7186146974563599\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics='accuracy')\n",
        "\n",
        "# change epoch values\n",
        "model.fit(X_train, Y_train, batch_size=20, epochs=50, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "T3QxF-qvsCL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2dfa29a-86d6-4f9c-f771-477410095cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 2s 9ms/step - loss: 0.1916 - accuracy: 0.7132 - val_loss: 0.1804 - val_accuracy: 0.7403\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1888 - accuracy: 0.7039 - val_loss: 0.1797 - val_accuracy: 0.7576\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1874 - accuracy: 0.7300 - val_loss: 0.1856 - val_accuracy: 0.7532\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.7151 - val_loss: 0.1997 - val_accuracy: 0.7100\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1899 - accuracy: 0.7151 - val_loss: 0.1839 - val_accuracy: 0.7662\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.7281 - val_loss: 0.1789 - val_accuracy: 0.7359\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1856 - accuracy: 0.7188 - val_loss: 0.1821 - val_accuracy: 0.7749\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1810 - accuracy: 0.7467 - val_loss: 0.1861 - val_accuracy: 0.7186\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.6853 - val_loss: 0.1858 - val_accuracy: 0.7186\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1872 - accuracy: 0.7207 - val_loss: 0.1853 - val_accuracy: 0.7100\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1888 - accuracy: 0.7169 - val_loss: 0.1861 - val_accuracy: 0.7186\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.1889 - accuracy: 0.7114 - val_loss: 0.1934 - val_accuracy: 0.6926\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1938 - accuracy: 0.7132 - val_loss: 0.1798 - val_accuracy: 0.7619\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1830 - accuracy: 0.7188 - val_loss: 0.1789 - val_accuracy: 0.7706\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1839 - accuracy: 0.7318 - val_loss: 0.1810 - val_accuracy: 0.7576\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1874 - accuracy: 0.7151 - val_loss: 0.1783 - val_accuracy: 0.7316\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1849 - accuracy: 0.7151 - val_loss: 0.1789 - val_accuracy: 0.7489\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.7374 - val_loss: 0.1785 - val_accuracy: 0.7403\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1864 - accuracy: 0.7095 - val_loss: 0.1910 - val_accuracy: 0.7403\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.7151 - val_loss: 0.1800 - val_accuracy: 0.7532\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.7225 - val_loss: 0.1793 - val_accuracy: 0.7403\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.7225 - val_loss: 0.1851 - val_accuracy: 0.7532\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.7318 - val_loss: 0.1801 - val_accuracy: 0.7532\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.7300 - val_loss: 0.1816 - val_accuracy: 0.7662\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1864 - accuracy: 0.7263 - val_loss: 0.1804 - val_accuracy: 0.7576\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 0.7300 - val_loss: 0.1808 - val_accuracy: 0.7532\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1828 - accuracy: 0.7374 - val_loss: 0.1807 - val_accuracy: 0.7619\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.7207 - val_loss: 0.1830 - val_accuracy: 0.7403\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1844 - accuracy: 0.7374 - val_loss: 0.1825 - val_accuracy: 0.7619\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.7188 - val_loss: 0.1784 - val_accuracy: 0.7706\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.7114 - val_loss: 0.1783 - val_accuracy: 0.7403\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.7114 - val_loss: 0.1781 - val_accuracy: 0.7532\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.7337 - val_loss: 0.1803 - val_accuracy: 0.7576\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1819 - accuracy: 0.7356 - val_loss: 0.1804 - val_accuracy: 0.7532\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1830 - accuracy: 0.7263 - val_loss: 0.1779 - val_accuracy: 0.7749\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1850 - accuracy: 0.7169 - val_loss: 0.1774 - val_accuracy: 0.7576\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.7300 - val_loss: 0.1772 - val_accuracy: 0.7576\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1839 - accuracy: 0.7263 - val_loss: 0.1786 - val_accuracy: 0.7316\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.7225 - val_loss: 0.1823 - val_accuracy: 0.7489\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 0.7356 - val_loss: 0.1890 - val_accuracy: 0.7229\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.7169 - val_loss: 0.1775 - val_accuracy: 0.7749\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.7225 - val_loss: 0.1843 - val_accuracy: 0.7403\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.7188 - val_loss: 0.1791 - val_accuracy: 0.7229\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1824 - accuracy: 0.7188 - val_loss: 0.1779 - val_accuracy: 0.7706\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.7318 - val_loss: 0.1787 - val_accuracy: 0.7489\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1813 - accuracy: 0.7374 - val_loss: 0.1792 - val_accuracy: 0.7229\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.7263 - val_loss: 0.1778 - val_accuracy: 0.7532\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.1813 - accuracy: 0.7318 - val_loss: 0.1793 - val_accuracy: 0.7792\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.1827 - accuracy: 0.7300 - val_loss: 0.1769 - val_accuracy: 0.7749\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.7244 - val_loss: 0.1786 - val_accuracy: 0.7316\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.7316\n",
            "Loss:  0.1786220371723175\n",
            "Accuracy:  0.7316017150878906\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}